{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d9d9ab-9041-49cd-a4f9-059c03cb09b9",
   "metadata": {},
   "source": [
    "# Notebook 1; Alternative brain eigenmodes:\n",
    "\n",
    "This notebook contains the scripts that generate several alternative brain eigenmodes that were used in our evaluations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b6764-f56e-4728-8453-766049b3c312",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preliminary scripts\n",
    "\n",
    "---\n",
    "\n",
    "These scripts load required packages and define useful functions that are used by this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f0839-1d38-485b-979b-9bc6a8f3d643",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Package imports\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fb501b-058d-44ab-9e2b-7d0fd5f74c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import importlib\n",
    "import itertools\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import scipy.sparse as sparse\n",
    "import scipy.stats as stats\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "import seaborn as sns\n",
    "import boto3\n",
    "import lapy\n",
    "import h5py\n",
    "from sklearn import linear_model\n",
    "\n",
    "# CSS used for computing local distances and connectome smoothing\n",
    "from Connectome_Spatial_Smoothing import CSS as css\n",
    "\n",
    "# Cerebro brain viewer used for visualization\n",
    "from cerebro import cerebro_brain_utils as cbu\n",
    "from cerebro import cerebro_brain_viewer as cbv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b37728-3641-4743-b962-fcfa655c9d04",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Basic functions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b626e5f-6ac7-480b-9789-8f1fad7dc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful functions\n",
    "\n",
    "class MyNumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(MyEncoder, self).default(obj)\n",
    "\n",
    "\n",
    "def ensure_dir(file_name):\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    return file_name\n",
    "\n",
    "\n",
    "def list_dirs(path=os.getcwd()):\n",
    "    files = glob.glob(os.path.join(path, '*'))\n",
    "    files = [x for x in files if os.path.isdir(x)]\n",
    "    return files\n",
    "\n",
    "\n",
    "def file_exists(file_name, path_name=os.getcwd()):\n",
    "    return os.path.isfile(os.path.join(path_name, file_name))\n",
    "\n",
    "\n",
    "def write_json(json_obj, file_path):\n",
    "    with open(file_path, 'w') as outfile:\n",
    "        json.dump(json_obj, outfile, sort_keys=True, indent=4,\n",
    "                  cls=MyNumpyEncoder)\n",
    "    return json_obj\n",
    "\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as infile:\n",
    "        return json.load(infile)\n",
    "\n",
    "\n",
    "def write_np(np_obj, file_path):\n",
    "    with open(file_path, 'wb') as outfile:\n",
    "        np.save(outfile, np_obj)\n",
    "\n",
    "\n",
    "def load_np(file_path):\n",
    "    with open(file_path, 'rb') as infile:\n",
    "        return np.load(infile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32417db2-aaa6-47d8-989f-bfdd32653b97",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Directory structure\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d24017-9138-4e24-8a6b-6dd0609b4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path setting\n",
    "main_dir = os.path.abspath('../')\n",
    "\n",
    "data_dir = f\"{main_dir}/data\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0109df-6828-483d-b6c8-cc7956b6e2ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Extracting mesh connectivity structure\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a83f1bcd-2df3-49dc-ab2c-cd21359720ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# basic parameters\n",
    "surface = 'midthickness_MSMAll'\n",
    "\n",
    "# load an example dscalar\n",
    "dscalar_file = f'{data_dir}/templates/ones.dscalar.nii'\n",
    "dscalar = nib.load(dscalar_file)\n",
    "\n",
    "brain_models = [x for x in dscalar.header.get_index_map(1).brain_models]\n",
    "\n",
    "# load surfaces for visualization\n",
    "left_surface_file = f'{data_dir}/templates/S1200.L.{surface}.32k_fs_LR.surf.gii'\n",
    "left_surface = nib.load(left_surface_file)\n",
    "right_surface_file = f'{data_dir}/templates/S1200.R.{surface}.32k_fs_LR.surf.gii'\n",
    "right_surface = nib.load(right_surface_file)\n",
    "\n",
    "# create a mapping between surface and cifti vertices\n",
    "left_cortical_surface_model, right_cortical_surface_model = brain_models[0], brain_models[1]\n",
    "cifti_to_surface = {}\n",
    "surface_to_cifti = {}\n",
    "for (i, x) in enumerate(left_cortical_surface_model.vertex_indices):\n",
    "    cifti_to_surface[i] = x\n",
    "    surface_to_cifti[x] = i\n",
    "for (i, x) in enumerate(right_cortical_surface_model.vertex_indices):\n",
    "    cifti_to_surface[i + right_cortical_surface_model.index_offset] = x + right_surface.darrays[0].data.shape[0]\n",
    "    surface_to_cifti[x + right_surface.darrays[0].data.shape[0]] = i + right_cortical_surface_model.index_offset\n",
    "\n",
    "# construct data over surface\n",
    "surface_mask = list(surface_to_cifti.keys())\n",
    "\n",
    "left_surface_mask = surface_mask[:right_cortical_surface_model.index_offset]\n",
    "right_surface_mask = surface_mask[right_cortical_surface_model.index_offset:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095bfd3-3870-4b8d-a057-374b1f303a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surface_indices_left_and_right_on_cifti(cifti=dscalar):\n",
    "    # load the brain models from the file (first two models are the left and right cortex)\n",
    "    brain_models = [x for x in cifti.header.get_index_map(1).brain_models]\n",
    "    # get the names of brain structures in the cifti file\n",
    "    structure_names = [x.brain_structure for x in brain_models]\n",
    "    \n",
    "    left_cortex_index = structure_names.index('CIFTI_STRUCTURE_CORTEX_LEFT')\n",
    "    right_cortex_index = structure_names.index('CIFTI_STRUCTURE_CORTEX_RIGHT')\n",
    "    \n",
    "    left_surfaces_cifti_indices = [x for x in brain_models[left_cortex_index].vertex_indices]\n",
    "    right_surfaces_cifti_indices = [x for x in brain_models[right_cortex_index].vertex_indices]\n",
    "    \n",
    "    return (left_surfaces_cifti_indices, right_surfaces_cifti_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb1842-ba6a-49f8-97fb-045bc032f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the cortical surfaces and a sample cifti file first\n",
    "left_surf = left_surface\n",
    "right_surf = right_surface\n",
    "\n",
    "cifti = dscalar\n",
    "\n",
    "\n",
    "# constructing the local connectivity for surfaces:\n",
    "left_surf_dim = left_surf.darrays[0].data.shape[0]\n",
    "left_surf_adj = sparse.dok_matrix((left_surf_dim, left_surf_dim), dtype=np.float32)\n",
    "\n",
    "for t in left_surf.darrays[1].data:\n",
    "    left_surf_adj[t[0], t[1]] = 1\n",
    "    left_surf_adj[t[1], t[0]] = 1\n",
    "    left_surf_adj[t[2], t[1]] = 1\n",
    "    left_surf_adj[t[1], t[2]] = 1\n",
    "    left_surf_adj[t[0], t[2]] = 1\n",
    "    left_surf_adj[t[2], t[0]] = 1\n",
    "\n",
    "\n",
    "right_surf_dim = right_surf.darrays[0].data.shape[0]\n",
    "right_surf_adj = sparse.dok_matrix((right_surf_dim, right_surf_dim), dtype=np.float32)\n",
    "\n",
    "for t in left_surf.darrays[1].data:\n",
    "    right_surf_adj[t[0], t[1]] = 1\n",
    "    right_surf_adj[t[1], t[0]] = 1\n",
    "    right_surf_adj[t[2], t[1]] = 1\n",
    "    right_surf_adj[t[1], t[2]] = 1\n",
    "    right_surf_adj[t[0], t[2]] = 1\n",
    "    right_surf_adj[t[2], t[0]] = 1\n",
    "\n",
    "left_surf_adj = left_surf_adj.tocsr()\n",
    "right_surf_adj = right_surf_adj.tocsr()\n",
    "\n",
    "left_surfaces_cifti_indices, right_surfaces_cifti_indices = get_surface_indices_left_and_right_on_cifti()\n",
    "\n",
    "# cortical surface local connectivity (excluding medial wall)\n",
    "left_surf_adj_selection = left_surf_adj[:,left_surfaces_cifti_indices][left_surfaces_cifti_indices,:]\n",
    "right_surf_adj_selection = right_surf_adj[:,right_surfaces_cifti_indices][right_surfaces_cifti_indices,:]\n",
    "\n",
    "# aggregating two cortical surfaces\n",
    "local_adjacency = sparse.block_diag((left_surf_adj_selection, right_surf_adj_selection))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314fb5cb-61b3-44a5-96a9-fdb289f58327",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_local_connections = left_surf_adj_selection.copy()\n",
    "left_local_connections.eliminate_zeros()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b66a370-8dfe-4a7e-a171-ebf17a24d074",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Graph Laplacian scripts\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b074e0-4cf6-47e6-91ce-4b8ccd701ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to compute the symmetric normalized adjacency\n",
    "def symmetric_normalized_adj(adj):\n",
    "    degree = sparse.diags(np.array(adj.sum(axis=0))[0])\n",
    "    inverse_degree_square_root = degree.copy()\n",
    "    inverse_degree_square_root.data **= -0.5\n",
    "    SNA = (inverse_degree_square_root*adj*inverse_degree_square_root)\n",
    "    return SNA\n",
    "\n",
    "\n",
    "# a function performing a symmetric laplacian eigenmode decomposition over a sparse adjacency structure\n",
    "def laplace_spectrum_rev(adj, k=500):\n",
    "    # use shift invert mode\n",
    "    lambdas, vectors = sparse.linalg.eigsh(\n",
    "        symmetric_normalized_adj(adj),\n",
    "        k=k+1,\n",
    "        which=\"LM\",\n",
    "    )\n",
    "\n",
    "    # convert to laplacian lambdas\n",
    "    lambdas = 1 - lambdas\n",
    "    lambda_idx = np.argsort(lambdas)\n",
    "    lambdas = lambdas[lambda_idx]\n",
    "    vectors = vectors[:, lambda_idx]\n",
    "    return (lambdas, vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f82b4a-c12a-48d8-8e2e-d82e52ac7504",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Connectome thresholding scripts\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8353f97-0249-4598-8add-ec00ff8a77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take sparse adjacency matrix and remove edges lower than a threshold\n",
    "def threshold_connectome(connectome, threshold):\n",
    "    connectome_thresholded = connectome.multiply(\n",
    "        connectome > threshold\n",
    "    )\n",
    "    connectome_thresholded.eliminate_zeros()\n",
    "    return connectome_thresholded\n",
    "\n",
    "def edge_count(connectome):\n",
    "    connectome.eliminate_zeros()\n",
    "    return (connectome.data.shape[0] - (connectome.diagonal() > 0).sum()) / 2\n",
    "\n",
    "def find_density_threshold(connectome, density, precision=1e-5, max_iterations=50):\n",
    "    # edge count to meet the desired density\n",
    "    full_edge_count = (np.prod(connectome.shape) - connectome.shape[0]) * 0.5\n",
    "    goal_edge_count = density * full_edge_count\n",
    "    edge_count_tolerance = precision * full_edge_count\n",
    "\n",
    "    # define a threshold range to search over\n",
    "    search_range = (connectome.data.min() / 1.01, connectome.data.max())\n",
    "    edge_count_range = (edge_count(connectome), 0)\n",
    "\n",
    "    # exit if desired density is greater than the connectome density\n",
    "    if goal_edge_count > edge_count_range[0]:\n",
    "        print(\n",
    "            f'Warning, connectome density ({edge_count_range[0] / full_edge_count}) '\n",
    "            f'is lower than desired density ({density}).'\n",
    "        )\n",
    "        return search_range[0]\n",
    "\n",
    "    # binary search with tolerance to find the threshold\n",
    "    old_threshold, old_edge_count = search_range[1], edge_count_range[1]\n",
    "    iterations = 0\n",
    "    while iterations < max_iterations:\n",
    "        iterations += 1\n",
    "        new_threshold = np.mean(search_range)\n",
    "        new_edge_count = edge_count(connectome > new_threshold)\n",
    "\n",
    "        # check if threshold is good enough\n",
    "        if abs(new_edge_count - goal_edge_count) < edge_count_tolerance:\n",
    "            break\n",
    "\n",
    "        elif new_edge_count > goal_edge_count:\n",
    "            search_range = (new_threshold, search_range[1])\n",
    "            edge_count_range = (new_edge_count, edge_count_range[1])\n",
    "\n",
    "        else:\n",
    "            search_range = (search_range[0], new_threshold)\n",
    "            edge_count_range = (edge_count_range[0], new_edge_count)\n",
    "\n",
    "        if iterations >= max_iterations:\n",
    "            print(\n",
    "                f'Warning, max iterations reached; goal density: {density}, '\n",
    "                f'achieved density: {new_edge_count / full_edge_count}'\n",
    "            )\n",
    "\n",
    "    print(f\"iterations: {iterations}, achieved density: {new_edge_count / full_edge_count}\")\n",
    "    return new_threshold\n",
    "\n",
    "# Function to compute density of a high-resolution connectome\n",
    "def density(adj):\n",
    "    full_edge_count = (np.prod(adj.shape) - adj.shape[0]) * 0.5\n",
    "    adj_edge_count = edge_count(adj)\n",
    "    return (adj_edge_count / full_edge_count)\n",
    "\n",
    "def report_density(connectome):\n",
    "    print(\"Connectome density: {:.1f}%\".format(100 * density(connectome)))\n",
    "\n",
    "def binarized_connectome(connectome):\n",
    "    return (connectome > 0).astype(float)\n",
    "\n",
    "def compute_and_store_eigenmodes(connectome, prefix, store_path=f\"{data_dir}/eigenmodes\"):\n",
    "    eigenvalues, eigenvectors = laplace_spectrum_rev(connectome)\n",
    "    write_np(eigenvectors, ensure_dir(f'{store_path}/{prefix}_eigenmodes.npy'))\n",
    "    \n",
    "def connectome_strength(connectome):\n",
    "    return np.array(connectome.sum(0))[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb4276c-b8eb-4626-8921-9cb53c156e47",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Connectome smoothing scripts\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71d832-3759-4417-82f6-998bebeee85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group-level surfaces to compute geodesic distance\n",
    "left_white_surface_file = f'{data_dir}/templates/S1200.L.white_MSMAll.32k_fs_LR.surf.gii'\n",
    "right_white_surface_file = f'{data_dir}/templates/S1200.R.white_MSMAll.32k_fs_LR.surf.gii'\n",
    "\n",
    "# CSS parameters\n",
    "fwhm = 8\n",
    "sigma = css._fwhm2sigma(fwhm)\n",
    "epsilon = 0.1\n",
    "max_smoothing_distance = css._max_smoothing_distance(sigma, epsilon, 2)\n",
    "\n",
    "# Local geodesic distance computed on the cortical surfaces\n",
    "cortical_local_geodesic_distances = css._get_cortical_local_distances(\n",
    "    left_white_surface_file,\n",
    "    right_white_surface_file,\n",
    "    max_smoothing_distance,\n",
    "    css._sample_cifti_dscalar\n",
    ")\n",
    "\n",
    "left_cortical_local_geodesic_distances = cortical_local_geodesic_distances[:right_cortical_surface_model.index_offset,:][:,:right_cortical_surface_model.index_offset]\n",
    "\n",
    "# Combine the two distance matrices and convert to smoothing coefficients\n",
    "left_smoothing_kernel = css._local_distances_to_smoothing_coefficients(\n",
    "    left_cortical_local_geodesic_distances,\n",
    "    sigma\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34704086-cf0d-46a2-818c-9213adc95199",
   "metadata": {},
   "source": [
    "## OSF deposited data:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "First, downloading data from Pang et al. (2023) that was deposited to [OSF](https://osf.io/xczmp/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d6388-7f85-49a2-bf81-76fb2d237a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir \"../data/pang\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e4caa-e588-4cb7-82e1-4d309ab6adc7",
   "metadata": {},
   "source": [
    "Note: If you are planning to replicate our scripts, in the following command, you should replace `<Data_URL>` with a download link acquired from [here](https://osf.io/xczmp/files/osfstorage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b7738-2f77-4cc1-9401-1c7c7f1484a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl -JL -o \"../data/pang/osf_data.zip\" <Data_URL>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb5acef-b4cc-426a-94e8-f41af88d1f4c",
   "metadata": {},
   "source": [
    "Once the data is downloaded, extract the compressed archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9990206-99d2-44a0-a45e-8ecca6eed7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical  osf_data.zip  results  template_eigenmodes\n"
     ]
    }
   ],
   "source": [
    "! ls \"../data/pang\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea1f54b-e9c5-4d26-b1b0-b19799c3a165",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "! unzip \"../data/pang/osf_data.zip\" -d \"../data/pang/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7729ac5a-fd09-458d-ac21-a977d0eeccc0",
   "metadata": {},
   "source": [
    "Load the eigenmodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f161aaf8-94b9-4215-8e20-77bf69298808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32492, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Geometry eigenmodes:\n",
    "pang_geometric_eigenmodes = np.genfromtxt(f\"{data_dir}/pang/results/basis_geometric_midthickness-lh_evec_200.txt\")\n",
    "\n",
    "pang_geometric_eigenmodes.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17525be9-5b0e-4295-acb8-c439e2a9cc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32492, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### EDR eigenmodes:\n",
    "with h5py.File(f\"{data_dir}/pang/results/basis_connectome_EDR_midthickness-lh_evec_200.mat\", 'r') as f:\n",
    "    pang_edr_eigenmodes = np.array(f['eig_vec']).T\n",
    "\n",
    "pang_edr_eigenmodes.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51876845-78b6-422b-ba7f-4360628ecea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32492, 200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Connectome eigenmodes:\n",
    "with h5py.File(f\"{data_dir}/pang/results/basis_connectome_midthickness-lh_evec_200.mat\", 'r') as f:\n",
    "    pang_connectome_eigenmodes = np.array(f['eig_vec']).T\n",
    "\n",
    "pang_connectome_eigenmodes.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fc2dd-b0e9-451b-b58d-966737ae9d86",
   "metadata": {},
   "source": [
    "Store the eigenmodes in a NumPy binary file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904d84e1-f8e0-4069-9d55-1f11f4ec08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of modes\n",
    "N_modes = 200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29913b03-cb71-40f3-8def-c3509e9f6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_np(\n",
    "    pang_geometric_eigenmodes[left_surface_mask, :N_modes],\n",
    "    ensure_dir(f\"{data_dir}/eigenmodes/pang_geometric_eigenmodes.npy\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b486d26-8f62-4791-979f-2b1cb455acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_np(\n",
    "    pang_edr_eigenmodes[left_surface_mask, :N_modes],\n",
    "    ensure_dir(f\"{data_dir}/eigenmodes/pang_edr_eigenmodes.npy\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25f165a5-24f0-417b-b5b1-46ae93498539",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_np(\n",
    "    pang_connectome_eigenmodes[left_surface_mask, :N_modes],\n",
    "    ensure_dir(f\"{data_dir}/eigenmodes/pang_connectome_eigenmodes.npy\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d728e55-5770-4248-836d-1c4acdc6fe87",
   "metadata": {},
   "source": [
    "In addition to the provided eigenmodes, we will also load and store the group-level structural connectome provided by Pang and colleagues. This is used by supplemental analytical evaluations present in our commentary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a32544e1-bec3-4482-8f4f-484c8ba790cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29696, 29696)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pang_connectome = sparse.csr_matrix(\n",
    "    sio.loadmat(\n",
    "        f\"{data_dir}/pang/empirical/S255_high-resolution_group_average_connectome_cortex_nomedial-lh.mat\"\n",
    "    )['avgSC_L']\n",
    ")\n",
    "pang_connectome.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6fefe4d-bb40-489e-85ee-0c9e1f8afeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz(\n",
    "    ensure_dir(f\"{data_dir}/connectomes/pang_group_average_connectome.npz\"),\n",
    "    pang_connectome\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846b8e4-5537-4248-af86-cc0c586becd5",
   "metadata": {},
   "source": [
    "## Our group-level connectome:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Using a recent tractography pipeline adhering to state-of-the-art connectome reconstruction decisions (detailed [here](https://doi.org/10.1016/j.neuroimage.2023.120407)), we mapped a similar group-level connectome from the identical set of HCP participants used by Pang and colleagues. The following cells loads our group-level connectome.\n",
    "\n",
    "**Note:** Please reach out to us in case you are keen to use these connectomes in your future research.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9f7a16-b3a5-41eb-960e-ff730ac7e205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29696, 29696)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_connectome = sparse.load_npz(f\"{data_dir}/connectomes/our_group_average_connectome.npz\")\n",
    "our_connectome.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403ee14-2c5b-4657-8c3c-9a27d68ce741",
   "metadata": {},
   "source": [
    "## Our connectome eigenmodes\n",
    "\n",
    "---\n",
    "\n",
    "In the main text of the analysis, we use connectome eigenmodes from a smoothed weighted graph constructed from the group-average connectome (loaded in the previous cell). These connectome eigenmodes were generated using the following script and are provided as part of this repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2720e5d-7c50-4952-a761-0cf1cc89e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform connectome-spatial smoothing\n",
    "smoothed_connectome = threshold_connectome(\n",
    "    css.smooth_high_resolution_connectome(\n",
    "        our_connectome,\n",
    "        left_smoothing_kernel\n",
    "    ), 1e-4\n",
    ")\n",
    "\n",
    "# 10% density\n",
    "threshold = find_density_threshold(smoothed_connectome, 0.1)\n",
    "smoothed_connectome = threshold_connectome(smoothed_connectome, threshold)\n",
    "\n",
    "# combine with local connections\n",
    "smoothed_connectome = smoothed_connectome + 1e-6 * left_local_connections\n",
    "\n",
    "# generate Laplacian eigenmodes\n",
    "compute_and_store_eigenmodes(smoothed_connectome, prefix=\"our_connectome\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ea322-e650-4f6a-9baa-aa96ac4389d8",
   "metadata": {},
   "source": [
    "### Supplementary connectome eigenmodes:\n",
    "\n",
    "---\n",
    "\n",
    "In addition to the connectome eigenmodes provided above, we performed supplementary evaluations to assess the sensitivity of the findings to different connectome reconstruction steps. The following cells contain the scripts that were used to generate the eigenmodes for our supplementary evaluations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d365ef6-e26a-41ba-a2f5-a4f8099a5658",
   "metadata": {},
   "source": [
    "#### Density increase:\n",
    "\n",
    "---\n",
    "\n",
    "We first evaluated the effect of increasing binary connectome density from 0.1% to 1%:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c358d9-cb73-4af4-be56-a5463855927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1% density\n",
    "threshold = find_density_threshold(pang_connectome, 0.01)\n",
    "connectome = threshold_connectome(pang_connectome, threshold)\n",
    "\n",
    "# combine with local connections\n",
    "connectome = connectome + left_local_connections\n",
    "\n",
    "# binarize\n",
    "connectome = binarized_connectome(connectome)\n",
    "\n",
    "# generate Laplacian eigenmodes\n",
    "compute_and_store_eigenmodes(connectome, prefix=\"1%_density_binary_connectome\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261826c-2487-4e24-8397-74765e905d00",
   "metadata": {},
   "source": [
    "#### Gyral bias mitigation:\n",
    "\n",
    "---\n",
    "\n",
    "Considering the visually evident presence of the gyral bias in Pang et al.'s connectome eigenmodes, we implemented two alternative approaches both of which were to alleviate the gyral bias prior to eigenmode construction. The following cells provide the scripts that produce the respective eigenmodes of these approaches. Notably, in both cases, the only variation is the gyral bias mitigation and the rest of eigenmode construction decisions are kept identical (i.e. 1% density, binary connectomes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718b725-3cc2-40ff-8661-4586d45f6086",
   "metadata": {},
   "source": [
    "##### Gyral bias: regression\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973acb38-8a3d-4204-aef8-4f72fd1a9756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to linearly regress effect of curvature from strength\n",
    "def regress_gyral_bias(connectome):\n",
    "    # load curvature information\n",
    "    curvature = nib.load(f\"{data_dir}/templates/S1200.curvature_MSMAll.32k_fs_LR.dscalar.nii\").get_fdata()[0]\n",
    "\n",
    "    # get left hemisphere curvature\n",
    "    node_dimension = connectome.shape[0]\n",
    "    curvature = curvature[:node_dimension].reshape(-1, 1)\n",
    "\n",
    "    # compute node strengths and degrees\n",
    "    node_strengths = np.array(connectome.sum(0)).reshape(-1, 1)\n",
    "    node_degrees = np.array((connectome > 0).sum(0)).reshape(-1, 1)\n",
    "\n",
    "    # fit a linear regressions\n",
    "    gyral_bias_predictions = linear_model.LinearRegression().fit(X=curvature, y=node_strengths).predict(curvature)\n",
    "\n",
    "    # remove the gyral bias effect from connectome\n",
    "    connectome_curvature_adjusted = connectome.tocoo()\n",
    "    indices = connectome_curvature_adjusted.row\n",
    "    connectome_curvature_adjusted.data -= 2 * (gyral_bias_predictions[indices, 0] / node_degrees[indices, 0])\n",
    "\n",
    "    # add constant to ensure connection weights are not negative\n",
    "    connectome_curvature_adjusted.data += 2 * (gyral_bias_predictions.max() / node_degrees[indices, 0])\n",
    "    connectome_curvature_adjusted = connectome_curvature_adjusted.tocsr()\n",
    "\n",
    "    # symmetric adjustment (to account for bias at both ends)\n",
    "    connectome_curvature_adjusted = (connectome_curvature_adjusted + connectome_curvature_adjusted.T)/2\n",
    "\n",
    "    # return adjusted connectome\n",
    "    return connectome_curvature_adjusted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbb36a-3ee4-4855-8a75-a447d6118fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress gyral bias\n",
    "connectome = regress_gyral_bias(pang_connectome)\n",
    "\n",
    "# 1% density\n",
    "threshold = find_density_threshold(connectome, 0.01)\n",
    "connectome = threshold_connectome(connectome, threshold)\n",
    "\n",
    "# combine with local connections\n",
    "connectome = connectome + left_local_connections\n",
    "\n",
    "# binarize\n",
    "connectome = binarized_connectome(connectome)\n",
    "\n",
    "# generate Laplacian eigenmodes\n",
    "compute_and_store_eigenmodes(connectome, prefix=\"1%_density_binary_gyral_bias_regression_connectome\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf516ad-3e58-49b5-9c65-8c3eb45ff8e9",
   "metadata": {},
   "source": [
    "##### Gyral bias: tractography\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6016f2-6726-4734-a541-33f86d349f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gyral bias mitigation in tractography \n",
    "connectome = our_connectome\n",
    "\n",
    "# 1% density\n",
    "threshold = find_density_threshold(connectome, 0.01)\n",
    "connectome = threshold_connectome(connectome, threshold)\n",
    "\n",
    "# combine with local connections\n",
    "connectome = connectome + left_local_connections\n",
    "\n",
    "# binarize\n",
    "connectome = binarized_connectome(connectome)\n",
    "\n",
    "# generate Laplacian eigenmodes\n",
    "compute_and_store_eigenmodes(connectome, prefix=\"1%_density_binary_gyral_bias_tractography_connectome\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3618aaf-6dc5-4623-bf5f-9a2cb7f0f180",
   "metadata": {},
   "source": [
    "#### Systematic evaluations:\n",
    "\n",
    "---\n",
    "\n",
    "In addition to the cases described above, we conducted a systematic evaluation of the influence of several connectome reconstruction decisions and parameters on reconstruction accuracy. These eigenmodes were constructed using automated scripts that were executed as parallel jobs on a high-performance computing platform (via slurm). The scripts used for this systematic evaluation can be found in the `scripts` folder of the repository.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda environment for normative modelling",
   "language": "python",
   "name": "pymc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
